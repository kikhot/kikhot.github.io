---
title: 哨兵模式
date: 2024-10-13 17:01:00
tags:
    - 面试题
    - redis
categories:
    - 面试题
    - redis
---
Redis提供了哨兵（Sentinel）机制来实现主从集群的自动故障恢复。哨兵的结构和作用如下：

+ **监控：**Sentinel会不断检查您的master和slave是否按预期工作
+ **自动故障恢复：**如果master故障，Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主
+ **通知：**Sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis客户端

![](../../../images/面试题/redis/image_27.png)

## <font style="color:rgb(255, 0, 1);">服务状态监控</font>
Sentinel基于心跳机制监测服务状态，每隔1秒向集群的每个实例发送ping命令：

+ **主观下线：**如果某sentinel节点发现某实例未在规定时间响应，则认为该实例**主观下线**。
+ **客观下线：**若超过指定数量（quorum）的sentinel都认为该实例主观下线，则该实例**客观下线**。quorum值最好超过Sentinel实例数量的一半。

![](../../../images/面试题/redis/image_28.png)

**哨兵选主规则**

+ 首先判断主与从节点断开时间长短，如超过指定值就排该从节点
+ 然后判断从节点的slave-priority值，越小优先级越高
+ <font style="color:rgb(255, 0, 1);">如果slave-prority一样，则判断slave节点的offset值，越大优先级越高</font>
+ 最后是判断slave节点的运行id大小，越小优先级越高

## <font style="color:rgb(255, 0, 1);">Redis集群（哨兵模式）脑裂</font>
当sentinel与master网络出现了问题，而客户端RedisClient还能正常连接，就会出现脑裂现象，也就是客户端写入数据是在master中，而sentinel因为网络问题监控不到老的master，会推出一个新的master。这样就会出现两个master。

而当网络恢复之后，哨兵会将老的master强制降为slave，这时降为slave的节点会同步master数据，从而将之前客户端写入的数据丢失

![](../../../images/面试题/redis/image_29.png)

![](../../../images/面试题/redis/image_30.png)

**解决方法：**

我们可以修改redis中的两个配置参数：

+ min-replicas-to-write 1		表示最少的slave节点为1个（<font style="color:rgb(255, 0, 1);">即主节点至少有一个slave才能接收新的数据</font>）
+ min-replicas-max-lag 5		表示数据复制和同步的延迟不能超过5秒



> **怎么保证Redis的高并发高可用**
> 
> 哨兵模式：实现主从集群的自动故障恢复（监控、自动故障恢复、通知）
> 
> **你们使用redis是单点还是集群，哪种集群**
> 
> 主从（1主1从）+哨兵就可以了。单节点不超过10G内存，如果Redis内存不足则可以给不同服务分配独立的Redis主从节点
> 
> **redis集群脑裂，该怎么解决呢？**
> 
> <font style="color:rgb(255, 0, 1);">集群脑裂</font>是由于主节点和从节点和sentinel处于不同的网络分区，使得sentinel没有能够心跳感知到主节点，所以通过选举的方式提升了一个从节点为主，这样就存在了两个master，就像大脑分裂了一样，这样会导致客户端还在老的主节点那里写入数据，新节点无法同步数据，当网络恢复后，sentinel会将老的主节点降为从节点，这时再从新master同步数据，就会导致数据丢失
> 
> **解决︰** 我们可以修改redis的配置，可以设置最少的从节点数量以及缩短主从数据同步的延迟时间，达不到要求就拒绝请求，就可以避免大量的数据丢失


--- 

## 面试场景
> **面试官：** 怎么保证redis的高并发高可用
> 
> **候选人：** 首先可以搭建主从集群，再加上使用redis中的哨兵模式，哨兵模式可以实现主从集群的自动故障恢复，里面就包含了对主从服务的监控、自动故障恢复、通知；如果master故障，Sentinel会将一个slave提升为提升为master。当故障实例恢复后也以新master的为主；同时Sentinel也充当redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis的客户端，所以一般项目都会采用哨兵的模式来保证redis的高并发高可用
> 
> **面试官：** 你们使用redis是单点还是集群，哪种集群
> 
> **候选人：** 嗯！，我们当时使用的是主从(1主1从)加哨兵。一般单节点不超过10G内存，如果redis内存不足则可以给不同服务分配独立的Redis主从节点。尽量不做分片集群。因为集群维护起来比较麻烦，并且集群之间的心跳检测和数据通信会消耗大量的网络带宽，也没有办法使用lua脚本和事务
> 
> **面试官：** redis集群脑裂，该怎么解决呢？
> 
> **候选人：** 嗯！这个在项目很少见，不过脑裂的问题是这样的，我们现在用的是redis的哨兵模式集群的有的时候由于网络等原因可能会出现脑裂的情况，就是说，由于redis master节点和redis salve节点和Sentinel处于不同的网络分区，使得Sentinel没有能够心跳感知到Master，所以通过选举的方式提升了一个salve为Master，这样就存在了两个Master，就像大脑分裂了一样，这样会导致客户端还在老主人那里写入数据，新节点无法同步数据，当网络恢复后，哨兵会将老主人降为Salve，这时再从新大师同步数据，这会导致老主人中的大量数据丢失。
> 
> 关于解决的话，我记得在redis的配置中可以设置：第一可以设置最少的salve节点个数，比如设置至少要有一个从节点才能同步数据，第二个可以设置主从数据复制和同步的延迟时间，达不到要求就拒绝请求，就可以避免大量的数据丢失


